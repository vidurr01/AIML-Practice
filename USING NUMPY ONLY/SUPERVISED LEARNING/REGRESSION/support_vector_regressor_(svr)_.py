# -*- coding: utf-8 -*-
"""Support Vector Regressor (SVR) .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CY8OxP0UpZscyq14693_LGT8ACB49PFM

# Importing modules
"""

import numpy as np
import pandas as pd
from sklearn.datasets import load_diabetes

"""# Loading Data

"""

data = load_diabetes()
X,y = data.data, data.target

"""# Feature Scaling

"""

X_mean, X_std = np.mean(X, axis = 0), np.std(X, axis = 0)
y_mean, y_std = np.mean(y, axis = 0), np.std(y, axis = 0)
X = (X - X_mean)/X_std
y = (y - y_mean)/y_std
print(X.shape, y.shape)

"""# Break Data into train, validation and test data"""

from sklearn.model_selection import train_test_split
train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.2,random_state=0)
train_X, val_X, train_y, val_y = train_test_split(train_X,train_y,test_size=0.2,random_state=0)

print(train_X.shape, train_y.shape)
print(val_X.shape, val_y.shape)
print(test_X.shape, test_y.shape)

"""# RBF Kernel function


"""

def K(X1,X2,gamma=0.1): #RBF Kernel function
  sq_dist = np.sum(X1**2,axis = 1).reshape(-1,1) + np.sum(X2**2,axis=1).reshape(1,-1) - 2*(X1@X2.T) #Mistake 1: Forgot reshape(-1,1) and (1,-1)
  return np.exp(-gamma*sq_dist)

"""# Kernelised Primal model training, validation and testing"""

alpha = np.zeros(train_X.shape[0]) #mistake 2: I did X.shape[1]
alpha_star = np.zeros(train_X.shape[0])
beta = alpha - alpha_star
b = 0

epochs = 2000
epsilon = 1e-5
C = 1
lr = 3e-5

K_train = K(train_X,train_X)
K_val = K(val_X,train_X)
K_test = K(test_X,train_X)
print(K_train.shape, K_val.shape, K_test.shape,beta.shape)

for epoch in range(epochs):
  train_y_pred = K_train@beta + b
  train_xi = np.maximum(0, train_y_pred - train_y - epsilon)
  train_xi_star = np.maximum(0, train_y - train_y_pred - epsilon)
  w_norm_sq = beta.T@K_train@beta
  train_J = 0.5 * w_norm_sq + C*np.sum(train_xi + train_xi_star)
  residual = train_y_pred - train_y
  mask_pos = (residual > epsilon).astype(np.float64) #Mistake 3: wrote int instead of float64
  mask_neg = (residual < -epsilon).astype(np.float64)
  dJ_dbeta = K_train @ beta + C * (K_train@(mask_pos - mask_neg).T)
  dJ_db = C * np.sum(mask_pos - mask_neg)
  beta -= lr*dJ_dbeta
  b -= lr*dJ_db

  if (epoch+1)%100==0:
    val_y_pred = K_val@beta + b
    mseloss = np.mean((val_y_pred - val_y)**2)
    print(f"Epoch {epoch+1}: val loss = {mseloss}")

test_y_pred = K_test@beta + b
mseloss = np.mean((test_y_pred - test_y)**2)
print(f"test loss = {mseloss}")

"""# Kernelised Dual model training, validation and testing"""

alpha = np.zeros(train_X.shape[0]) #mistake 2: I did X.shape[1]
alpha_star = np.zeros(train_X.shape[0])
beta = alpha - alpha_star
b = 0

epochs = 2000
epsilon = 1e-5
C = 1
lr = 3e-5

K_train = K(train_X,train_X)
K_val = K(val_X,train_X)
K_test = K(test_X,train_X)
print(K_train.shape, K_val.shape, K_test.shape,beta.shape)

for epoch in range(epochs):
  train_y_pred = K_train@beta + b
  train_W = -0.5 * (beta.T@K_train@beta) - epsilon * np.sum(alpha + alpha_star) + np.sum(train_y * beta) #must be maximized
  dW_dalpha = - K_train@beta - epsilon + train_y
  dW_dalpha_star = K_train@beta - epsilon - train_y
  alpha += lr*dW_dalpha
  alpha_star += lr*dW_dalpha_star
  alpha -= 0.5* np.sum(alpha-alpha_star)/len(alpha) # to make np.sum(alpha - alpha*) = 0
  alpha_star += 0.5* np.sum(alpha-alpha_star)/len(alpha_star)# to make np.sum(alpha - alpha*) = 0
  alpha = np.clip(alpha,0,C)
  alpha_star = np.clip(alpha_star,0,C)
  beta = alpha - alpha_star
  b = np.mean(- K_train@beta - epsilon + train_y)

  if (epoch+1)%100==0:
    val_y_pred = K_val@beta + b
    mseloss = np.mean((val_y_pred - val_y)**2)
    print(f"Epoch {epoch+1}: val loss = {mseloss}")

test_y_pred = K_test@beta + b
mseloss = np.mean((test_y_pred - test_y)**2)
print(f"test loss = {mseloss}")